{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yi-69wghypvB"
   },
   "source": [
    "#위스콘신 유방암 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "StcLIsGCwlAh",
    "outputId": "ab7a1c3e-603e-4913-bb3d-4616735fd181"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "data = cancer.data\n",
    "label = cancer.target\n",
    "\n",
    "data_df = pd.DataFrame(data, columns = cancer.feature_names)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7MieHBf1byw"
   },
   "source": [
    "#decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUokg0r2joiJ",
    "outputId": "08f9c585-65e3-4585-9688-6a0fa14f1d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.915603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "scores = cross_val_score(dt_clf, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPTIp65o1ftQ"
   },
   "source": [
    "#boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yySImUX01iH_"
   },
   "source": [
    "##adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4B8-8hwelg_",
    "outputId": "0bc33c7e-c3ee-4e74-a3d5-dc586f20133b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.975423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=200, random_state=123)\n",
    "\n",
    "scores = cross_val_score(ada_clf, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5Wual6l1kui"
   },
   "source": [
    "##xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8S19BbARjPnL",
    "outputId": "fe669c80-ab93-4a62-d695-982f1c3c77df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=200, random_state=123)\n",
    "\n",
    "scores = cross_val_score(xgb_clf, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIi0fI38G45o"
   },
   "source": [
    "##lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YC8goazCGw8Y",
    "outputId": "2c18855b-a398-49fe-869d-923045bff7be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.973653\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=300, random_state=123)\n",
    "\n",
    "scores = cross_val_score(lgbm_clf, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk0xzLjU1qVG"
   },
   "source": [
    "#bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pBFZQxe-Z-wP",
    "outputId": "dea7212b-021a-46d3-92b4-17bb6c88f29d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.963111\n"
     ]
    }
   ],
   "source": [
    "#코드 구동에 약 10초가 소요됩니다.\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_features=\"auto\", max_leaf_nodes=16, random_state=123), \n",
    "    n_estimators=200, max_samples=1.0, bootstrap=True, n_jobs=-1, random_state=123)\n",
    "\n",
    "scores = cross_val_score(bag_clf, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5fAM7791vvF"
   },
   "source": [
    "##random forest\n",
    "decision tree에 배깅을 적용한 것이 random forest이므로 위의 코드와 성능이 비슷할 것으로 예측된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGhmfiAGkH12",
    "outputId": "9a5a0576-ff86-4204-c9f5-3e6cc68cb1e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.959618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, max_leaf_nodes=16, n_jobs=-1, random_state=123)\n",
    "\n",
    "scores = cross_val_score(rf_clf, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mC15NXuKlxtX"
   },
   "source": [
    "##배깅 직접 구현\n",
    "배깅의 직접 구현도 어렵지 않다. 하는 김에 소프트보팅 방법도 직접 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zeE3jbIUl3xb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size = 0.2, random_state = 123)\n",
    "\n",
    "bagging_pred = [] #각 모델들의 레이블 예측\n",
    "bagging_predict_proba = [] #각 모델들의 레이블에 속할 확률 예측\n",
    "bagging_predict_result = [] #test set으로 평가한 각 모델들의 accuracy\n",
    "\n",
    "for _ in range(10):  \n",
    "    # 반복 복원추출과정. 중복을 허용하지 않음으로 인해 페이스팅을 구현하고자 한다면 np.random.choice에서 replace=False로 설정하면 된다. default 값은 True이다.\n",
    "    data_index = [data_index for data_index in range(X_train.shape[0])]\n",
    "    random_data_index = np.random.choice(data_index, X_train.shape[0]) \n",
    "    \n",
    "    # decision tree\n",
    "    bg_X_train = pd.DataFrame(X_train).iloc[random_data_index,]\n",
    "    bg_y_train = pd.DataFrame(y_train).iloc[random_data_index,]\n",
    "    dt_clf.fit(bg_X_train, bg_y_train)\n",
    "\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    bagging_pred.append(dt_clf.predict(X_test))\n",
    "    bagging_predict_proba.append(dt_clf.predict_proba(X_test))\n",
    "    bagging_predict_result.append(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvHSsZoumbpf",
    "outputId": "0dde4414-6c6a-454b-8a46-80c4a8c1635f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.956140350877193,\n",
       " 0.9385964912280702,\n",
       " 0.956140350877193,\n",
       " 0.956140350877193,\n",
       " 0.9298245614035088,\n",
       " 0.9210526315789473,\n",
       " 0.9649122807017544,\n",
       " 0.9473684210526315,\n",
       " 0.9473684210526315,\n",
       " 0.9035087719298246]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델들 예측 결과\n",
    "bagging_predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-QYQpw0qHRk",
    "outputId": "35de86ad-1e6f-475e-8104-8aa51fa5317e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# 최종 결과. 각 모델들의 예측 확률을 소프트 보팅 방법으로 합한 후 대소비교를 통해 최종 레이블을 0 또는 1로 결정해주었다. \n",
    "last_proba = np.zeros_like(bagging_predict_proba[0])\n",
    "for i in range(10) :\n",
    "    last_proba += bagging_predict_proba[i]\n",
    "last_pred = np.zeros_like(bagging_pred[0])\n",
    "for i in range(len(last_proba)) :\n",
    "    last_pred[i] = 0 if last_proba[i][0] >= last_proba[i][1] else 1\n",
    "  \n",
    "print(accuracy_score(y_test, last_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpJ65rE8IepA"
   },
   "source": [
    "부스팅 모델들에 배깅을 적용할 수는 없을까?\n",
    "##bagged xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PnI79cbsbsoo",
    "outputId": "de120cd6-42fb-46fd-f67b-c4a977f81c4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.96662\n"
     ]
    }
   ],
   "source": [
    "#코드 구동에 약 2분이 소요됩니다.\n",
    "bag_xgb_clf = BaggingClassifier(\n",
    "    XGBClassifier(max_features = \"auto\", n_estimators=200, random_state=123), \n",
    "    n_estimators= 200, max_samples=1.0, bootstrap=True, n_jobs=-1, random_state=123)\n",
    "\n",
    "scores = cross_val_score(bag_xgb_clf, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzy_14IQI5Kg"
   },
   "source": [
    "##bagged lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5HpGYDhaKZu",
    "outputId": "b4b86bd5-5fa1-427a-a1e9-62c8ebeb31ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.973638\n"
     ]
    }
   ],
   "source": [
    "#코드 구동에 약 4분이 소요됩니다.\n",
    "bag_lgbm_clf = BaggingClassifier(\n",
    "    LGBMClassifier(max_features = \"auto\", n_estimators=300, random_state=123), \n",
    "    n_estimators= 200, max_samples=1.0, bootstrap=True, n_jobs=-1, random_state=123)\n",
    "\n",
    "scores = cross_val_score(bag_lgbm_clf, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vvm6Scqz15i7"
   },
   "source": [
    "#voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yqX71dbEc8q"
   },
   "source": [
    "##hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eai0yx2j2AWb",
    "outputId": "b625f37b-7b07-43fc-e340-a37907245514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.975408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vo_clf1 = VotingClassifier(estimators = [('ada',ada_clf), ('xgb',xgb_clf)], voting = 'hard')\n",
    "\n",
    "scores = cross_val_score(vo_clf1, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htJ7-PTGEe1M"
   },
   "source": [
    "##soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZK6WJwKEZOo",
    "outputId": "be298ef5-074a-4207-cd4c-cdfcbda38c10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.973638\n"
     ]
    }
   ],
   "source": [
    "vo_clf2 = VotingClassifier(estimators = [('ada',ada_clf), ('xgb',xgb_clf)], voting = 'soft')\n",
    "\n",
    "scores = cross_val_score(vo_clf2, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_TEFN-8GEWl"
   },
   "source": [
    "사이킷런은 weighted average를 활용한 soft voting 또한 지원한다. 보통 점수가 더 잘 나오는 쪽에 가중치를 크게 주면 높은 점수를 기대할 수 있다. 그러나 cv셋에 따라 오버피팅의 가능성이 있으니 주의하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSyRRkCYF8YA",
    "outputId": "a3d20c18-f8ba-412f-df83-8fe5811fffd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.975392\n"
     ]
    }
   ],
   "source": [
    "vo_clf3 = VotingClassifier(estimators = [('ada',ada_clf), ('xgb',xgb_clf)], voting = 'soft', weights = [0.7, 0.3])\n",
    "\n",
    "scores = cross_val_score(vo_clf3, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "co7fdt4RFOu9"
   },
   "source": [
    "분류기간의 성능 차이가 크면 아래처럼 좋은 앙상블 결과를 기대하기 힘들다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ua8gbVm2FEne",
    "outputId": "551d4677-6e55-4a8e-ae01-210e69ace2aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.934995\n"
     ]
    }
   ],
   "source": [
    "vo_clf4 = VotingClassifier(estimators = [('tree',dt_clf), ('xgb',xgb_clf)], voting = 'soft')\n",
    "\n",
    "scores = cross_val_score(vo_clf4, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfWTk0zTHHzr"
   },
   "source": [
    "3개 이상의 분류기의 앙상블도 물론 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNS9njmmHHNW",
    "outputId": "49e6b2fb-5247-4076-9220-b0af99f70ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.971883\n"
     ]
    }
   ],
   "source": [
    "vo_clf5 = VotingClassifier(estimators = [('ada',ada_clf), ('xgb',xgb_clf), ('lgbm', lgbm_clf)], voting = 'hard')\n",
    "\n",
    "scores = cross_val_score(vo_clf5, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBkINExZ15u1"
   },
   "source": [
    "#stacking\n",
    "핸즈온 머신러닝에서는 사이킷런이 스태킹을 직접 지원하지 않는다고 하지만, 업데이트가 된 것인지 찾아보니 지원하는 모듈이 있었다. 심지어 default로 stratified 5-fold를 이용하여 테스트 셋을 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Vlm8qkXN2TO",
    "outputId": "0b045ed4-4fa0-43e9-b4ae-5d5359d45255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:16:01] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:02] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:03] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:03] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:03] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:03] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:03] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:05] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:05] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:05] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:05] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:05] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:05] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:07] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:07] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:07] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:07] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:07] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:07] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:09] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:09] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:09] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:09] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:16:09] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:09] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:11] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:11] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:11] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:11] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:16:11] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "cv score :  0.975408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "st_clf = StackingClassifier(estimators=[('ada',ada_clf), ('xgb',xgb_clf)])\n",
    "\n",
    "scores = cross_val_score(st_clf, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gy0ZiwE4Ohhe"
   },
   "source": [
    "final_estimator를 다른 분류기로 설정할 수 있다. default는 linear regressor이다.\n",
    "그 외에 다양한 튜닝법은 사이킷런 레퍼런스에 자세히 설명되어 있다.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html?highlight=stacking#sklearn.ensemble.StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQTuBv26aKaS",
    "outputId": "7d5b8e47-31e5-412f-c53e-f40a793021db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.971914\n"
     ]
    }
   ],
   "source": [
    "#코드 구동에 약 1분이 소요됩니다.\n",
    "st_clf = StackingClassifier(estimators=[('ada',ada_clf), ('xgb',xgb_clf), ('rf', rf_clf)], final_estimator=LGBMClassifier())\n",
    "\n",
    "scores = cross_val_score(st_clf, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V45CPpZmabQK"
   },
   "source": [
    "##stacking 직접 구현(1)\n",
    "스태킹 직접 구현 또한 어렵지 않으니 해보도록 하자. 파머완 코드를 참고했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRzo0EYQb5QO",
    "outputId": "c2802e45-4ff4-4ad1-9818-b86785ef7a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:16:54] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "dt 정확도 : 0.956140350877193\n",
      "rf 정확도 : 0.9912280701754386\n",
      "ada 정확도 : 0.9649122807017544\n",
      "xgb 정확도 : 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_final = LogisticRegression(C=10, random_state=123)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "ada_pred = ada_clf.predict(X_test)\n",
    "xgb_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "print('dt 정확도 :',accuracy_score(y_test, dt_pred))\n",
    "print('rf 정확도 :',accuracy_score(y_test, rf_pred))\n",
    "print('ada 정확도 :',accuracy_score(y_test, ada_pred))\n",
    "print('xgb 정확도 :',accuracy_score(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTLhs6myoRed",
    "outputId": "138606c8-a59d-4eac-8a74-2130d615c0cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 114)\n",
      "(114, 4)\n"
     ]
    }
   ],
   "source": [
    "#각 예측값을 하나의 배열에 담는다.\n",
    "stacked_pred = np.array([dt_pred, rf_pred, ada_pred, xgb_pred])\n",
    "print(stacked_pred.shape)\n",
    "\n",
    "# transpose를 이용해 행과 열의 위치를 교환한다.\n",
    "stacked_pred = np.transpose(stacked_pred)\n",
    "print(stacked_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CW9USQ8bo9eh",
    "outputId": "bea6caaf-7fe8-4ed5-9851-aa89d533cdb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델 정확도 :  0.9912280701754386\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(stacked_pred, y_test)\n",
    "final_pred = lr_final.predict(stacked_pred)\n",
    "\n",
    "print('최종 메타 모델 정확도 : ',accuracy_score(y_test, final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G39fEBHp1oJ"
   },
   "source": [
    "위의 스태킹 모델은 y_test를 학습했기에 과적합 문제가 발생할 수 있다. (랜덤 시드에 따라 정확도가 1.0이 되기도 한다.)\n",
    "##stacking 직접 구현(2)\n",
    "cv세트 기반의 신뢰할만한 스태킹 모델을 직접 구현하자. 파머완에서는 kfold를 사용했지만 여기서는 stratifiedkfold를 이용해 구현하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EaINrSpq00q"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    # 지정된 n_folds 값으로 KFold 생성\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=False, random_state=123)\n",
    "    \n",
    "    # 추후 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
    "    print(model.__class__.__name__,' model 시작')\n",
    "    \n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n, y_train_n)):\n",
    "        # 입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 세트 추출\n",
    "        print('\\t 폴드 세트: ',folder_counter+1,' 시작')\n",
    "        X_tr = X_train_n[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        X_te = X_train_n[valid_index]\n",
    "        \n",
    "        # 폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행\n",
    "        model.fit(X_tr, y_tr)\n",
    "        # 폴드 세트 내부에서 다시 만들어지 검증 데이터로 기반 모델 예측 후 데이터 저장\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1, 1)\n",
    "        # 입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "        \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)\n",
    "    \n",
    "    # train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKi2kmLPuEso",
    "outputId": "f73f7b64-0345-4f48-fd90-12db3ed031f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier  model 시작\n",
      "\t 폴드 세트:  1  시작\n",
      "\t 폴드 세트:  2  시작\n",
      "\t 폴드 세트:  3  시작\n",
      "\t 폴드 세트:  4  시작\n",
      "\t 폴드 세트:  5  시작\n",
      "RandomForestClassifier  model 시작\n",
      "\t 폴드 세트:  1  시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 폴드 세트:  2  시작\n",
      "\t 폴드 세트:  3  시작\n",
      "\t 폴드 세트:  4  시작\n",
      "\t 폴드 세트:  5  시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier  model 시작\n",
      "\t 폴드 세트:  1  시작\n",
      "\t 폴드 세트:  2  시작\n",
      "\t 폴드 세트:  3  시작\n",
      "\t 폴드 세트:  4  시작\n",
      "\t 폴드 세트:  5  시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier  model 시작\n",
      "\t 폴드 세트:  1  시작\n",
      "\t 폴드 세트:  2  시작\n",
      "\t 폴드 세트:  3  시작\n",
      "\t 폴드 세트:  4  시작\n",
      "\t 폴드 세트:  5  시작\n"
     ]
    }
   ],
   "source": [
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test, 5)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 5)\n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 5)\n",
    "xgb_train, xgb_test = get_stacking_base_datasets(xgb_clf, X_train, y_train, X_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOrruEliwDKi",
    "outputId": "6c3056c0-f045-409a-a632-849d92041a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 학습 피처 데이터 shape: (455, 30) 원본 테스트 피처 shape: (114, 30)\n",
      "스태킹 학습 피처 데이터 shape: (455, 4) 스태킹 테스트 피처 데이터 shape: (114, 4)\n"
     ]
    }
   ],
   "source": [
    "Stack_final_X_train = np.concatenate((dt_train, rf_train, ada_train, xgb_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((dt_test, rf_test, ada_test, xgb_test), axis=1)\n",
    "print('원본 학습 피처 데이터 shape:', X_train.shape, '원본 테스트 피처 shape:',X_test.shape)\n",
    "print('스태킹 학습 피처 데이터 shape:',Stack_final_X_train.shape,\n",
    "     '스태킹 테스트 피처 데이터 shape:',Stack_final_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMrYQqIOwZEj",
    "outputId": "097145d9-4f90-4ca1-c4ea-4f26c547d75e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도:  0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(Stack_final_X_train, y_train)\n",
    "stack_final = lr_final.predict(Stack_final_X_test)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: ', accuracy_score(y_test, stack_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rD5aqwx5kluJ"
   },
   "source": [
    "#과제 : 천하제일 오버피팅 대회\n",
    "데이터는 위스콘신 유방암 데이터이고, 평가지표는 위의 코드들과 같이 같이 stratified 5-fold cv score입니다. 점수를 위해서라면 어떤 코드라도 작성하셔도 됩니다. 여러분의 하이퍼 패러미터 튜닝 / 앙상블 실력을 보여주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "aMNIeJNzlXGo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score :  0.97893184\n"
     ]
    }
   ],
   "source": [
    "#코드\n",
    "#--------------------------------------------------------------------\n",
    "xgb_clf = XGBClassifier(n_estimators=1000,gamma=0,n_jobs=-1,\n",
    "                        objective='binary:logistic',\n",
    "                       eval_metric='logloss',random_state=150)\n",
    "ada_clf = AdaBoostClassifier(n_estimators=1000,random_state=150)\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1,random_state=150)\n",
    "lr_clf = LogisticRegression(C=100,random_state=123)\n",
    "lgbm = LGBMClassifier(n_estimators=1000,scale_pos_weight=1.1,random_state=150)\n",
    "\n",
    "st_clf = StackingClassifier(estimators=[('xgb',xgb_clf), ('rf', rf_clf),('lgbm',lgbm)],\n",
    "                            final_estimator=lr_clf)\n",
    "\n",
    "vo = VotingClassifier(estimators = [('ada',ada_clf),('lgbm',lgbm),('xgb',xgb_clf),('lr',lr_clf)], voting = 'soft')\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "#점수 산정만 가능하다면 밑의 두 줄 또한 얼마든지 바꾸셔도 됩니다.\n",
    "scores = cross_val_score(vo, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('cv score : ', np.round(np.mean(scores), 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv score :  0.97893184"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BOAZ 멘멘 결정트리&앙상블.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
